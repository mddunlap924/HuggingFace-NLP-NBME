{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\"\"\" USER INPUTS \"\"\"\n",
    "MODEL_GROUPS = ['17y1th7h'] # Models to use for inference\n",
    "LOCATION = 'Local'  # Local vs. Kaggle Run Directories\n",
    "\n",
    "# https://arthought.com/transformer-model-fine-tuning-for-text-classification-with-pytorch-lightning/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transformer': PosixPath('venv/lib/python3.9/site-packages/transformers'), 'input': PosixPath('input')}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "\n",
    "if LOCATION == 'Local':\n",
    "    transformer_path = Path('./venv/lib/python3.9/site-packages/transformers')\n",
    "    input_dir = Path('./input')\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "    from nlp.datasets import TestDataset\n",
    "elif LOCATION == 'Kaggle':\n",
    "    transformer_path = Path('/opt/conda/lib/python3.7/site-packages/transformers')\n",
    "    input_dir = Path('../input')\n",
    "    %env TOKENIZERS_PARALLELISM=true\n",
    "    from nlp_datasets import TestDataset\n",
    "\n",
    "PATHS = {'transformer': transformer_path,\n",
    "         'input': input_dir }\n",
    "print(PATHS)\n",
    "\n",
    "CSV_DATA_PATH = os.path.join(PATHS['input'], 'nbme-score-clinical-patient-notes')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "# This must be done before importing transformers\n",
    "import shutil\n",
    "\n",
    "transformers_path = PATHS['transformer']\n",
    "input_dir = PATHS['input'] / 'deberta-v2-3-fast-tokenizer'\n",
    "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "conversion_path = transformers_path / convert_file.name\n",
    "if conversion_path.exists():\n",
    "    conversion_path.unlink()\n",
    "shutil.copy(convert_file, transformers_path)\n",
    "deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n",
    "    filepath = deberta_v2_path / filename\n",
    "    if filepath.exists():\n",
    "        filepath.unlink()\n",
    "    shutil.copy(input_dir / filename, filepath)\n",
    "from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    ")\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import f1_score\n",
    "import ast\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-17T22:45:28.978084Z",
     "iopub.execute_input": "2022-03-17T22:45:28.978481Z",
     "iopub.status.idle": "2022-03-17T22:45:36.068929Z",
     "shell.execute_reply.started": "2022-03-17T22:45:28.978446Z",
     "shell.execute_reply": "2022-03-17T22:45:36.068106Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def create_labels_for_scoring(df):\n",
    "    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n",
    "    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, 'location']\n",
    "        if lst:\n",
    "            new_lst = ';'.join(lst)\n",
    "            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df['location_for_create_labels'].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, predictions, tokenizer):\n",
    "    results = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "        encoded = tokenizer(text,\n",
    "                            add_special_tokens=True,\n",
    "                            return_offsets_mapping=True)\n",
    "        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n",
    "            start = offset_mapping[0]\n",
    "            end = offset_mapping[1]\n",
    "            results[i][start:end] = pred\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_results(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def dict2obj(d):\n",
    "    # checking whether object d is a\n",
    "    # instance of class list\n",
    "    if isinstance(d, list):\n",
    "        d = [dict2obj(x) for x in d]\n",
    "\n",
    "        # if d is not a instance of dict then\n",
    "    # directly object is returned\n",
    "    if not isinstance(d, dict):\n",
    "        return d\n",
    "\n",
    "    # declaring a class\n",
    "    class C:\n",
    "        pass\n",
    "\n",
    "    # constructor of the class passed to obj\n",
    "    obj = C()\n",
    "\n",
    "    for k in d:\n",
    "        obj.__dict__[k] = dict2obj(d[k])\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "def get_char_probs(texts, predictions, tokenizer):\n",
    "    \"\"\" Probability for each Character \"\"\"\n",
    "    results = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "        encoded = tokenizer(text,\n",
    "                            add_special_tokens=True,\n",
    "                            return_offsets_mapping=True)\n",
    "        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n",
    "            start = offset_mapping[0]\n",
    "            end = offset_mapping[1]\n",
    "            results[i][start:end] = pred\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_results(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def list_model_folds(group_id):\n",
    "    \"\"\" List all models and their files (i.e., *.ckpt and *.config) \"\"\"\n",
    "    list_models = []\n",
    "    filelist = []\n",
    "    model_group = os.path.join(PATHS['input'], 'nbme-' + group_id)\n",
    "\n",
    "    for root, dirs, files in os.walk(model_group):\n",
    "        for file in files:\n",
    "            # append the file name to the list\n",
    "            filelist.append(os.path.join(root, file))\n",
    "\n",
    "    model_folds = []\n",
    "    for filelist_ in filelist:\n",
    "        # fold_id = filelist_.split(model_group)[-1].split(f'/{group_id}/')[-1].split('/')[1].split('_')[-1]\n",
    "        fold_id = filelist_.split('_')[-1].split('/')[0]\n",
    "        if fold_id not in model_folds:\n",
    "            model_folds.append(fold_id)\n",
    "\n",
    "    config, ckpt = None, None\n",
    "    for model_fold in model_folds:\n",
    "        for filelist_ in filelist:\n",
    "            if (model_fold in filelist_) and ('.yaml' in filelist_):\n",
    "                config = filelist_\n",
    "            if (model_fold in filelist_) and ('.ckpt' in filelist_):\n",
    "                ckpt = filelist_\n",
    "        list_models.append([config, ckpt])\n",
    "    return list_models\n",
    "\n",
    "\"\"\" List all models and files for prediction \"\"\"\n",
    "all_model_files = []\n",
    "for MODEL_GROUP in MODEL_GROUPS:\n",
    "    model_folds = list_model_folds(group_id=MODEL_GROUP)\n",
    "    for model_fold in model_folds:\n",
    "        all_model_files.append(model_fold)\n",
    "\n",
    "print(all_model_files)\n",
    "for all_model_file in all_model_files:\n",
    "    print(f'Model Files: {all_model_file}')\n",
    "\n",
    "print('check here')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-17T22:45:36.145762Z",
     "iopub.execute_input": "2022-03-17T22:45:36.146418Z",
     "iopub.status.idle": "2022-03-17T22:45:36.165587Z",
     "shell.execute_reply.started": "2022-03-17T22:45:36.146380Z",
     "shell.execute_reply": "2022-03-17T22:45:36.164748Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['input/nbme-17y1th7h/17y1th7h_zi09ze76/config.yaml', 'input/nbme-17y1th7h/17y1th7h_zi09ze76/epoch=2-step=4289.ckpt']]\n",
      "Model Files: ['input/nbme-17y1th7h/17y1th7h_zi09ze76/config.yaml', 'input/nbme-17y1th7h/17y1th7h_zi09ze76/epoch=2-step=4289.ckpt']\n",
      "check here\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class BaseLineModel(pl.LightningModule):\n",
    "    def __init__(self, model_repo, *,\n",
    "                 autoconfig_path=None,\n",
    "                 automodel_path=None,\n",
    "                 learning_rate: float = 2e-5,\n",
    "                 adam_epsilon: float = 1e-8,\n",
    "                 warmup_steps: int = 0,\n",
    "                 weight_decay: float = 0.0,\n",
    "                 dropout_rate=0.1,\n",
    "                 th: float = 0.5,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        print(f'Save Hyperparameters: {self.save_hyperparameters()}')\n",
    "        self.th = th\n",
    "        if autoconfig_path is None:\n",
    "            autoconfig_path = PATHS['input'] / self.hparams.model_repo / 'config.json'\n",
    "        if automodel_path is None:\n",
    "            automodel_path = PATHS['input'] / self.hparams.model_repo\n",
    "\n",
    "        print(f'Loading AutoConfig inside Model Class: {autoconfig_path}')\n",
    "        self.config = AutoConfig.from_pretrained(autoconfig_path, output_hidden_states=True)\n",
    "        print('\\tLoaded AutoConfig inside Model Class')\n",
    "        print(f'Loading AutoModel inside Model Class: {automodel_path}')\n",
    "        self.base = AutoModel.from_pretrained(automodel_path, config=self.config)\n",
    "        print('\\tLoaded AutoModel inside Model Class')\n",
    "        self.fc_dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.base(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        return last_hidden_states\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        outs = self.fc(self.fc_dropout(feature))\n",
    "        return outs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels, idx = batch\n",
    "        y_preds = self(inputs)\n",
    "        loss = nn.BCEWithLogitsLoss(reduction=\"none\")(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        # return {\"loss\": loss, \"preds\": y_preds.detach(), \"labels\": labels.detach(), \"idxs\": idx.detach()}\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels, idx = batch\n",
    "        preds = self(inputs)\n",
    "        val_loss = nn.BCEWithLogitsLoss(reduction=\"none\")(preds.view(-1, 1), labels.view(-1, 1))\n",
    "        val_loss = torch.masked_select(val_loss, labels.view(-1, 1) != -1).mean()\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "        return {\"loss\": val_loss, \"preds\": preds, \"labels\": labels, \"idxs\": idx}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Prepare optimizer and schedule (linear warmup and decay)\"\"\"\n",
    "        model = self\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.hparams.learning_rate,\n",
    "                          eps=self.hparams.adam_epsilon)\n",
    "        return [optimizer]\n",
    "\n",
    "    def training_epoch_end(self, train_step_outputs):\n",
    "        if not self.trainer.sanity_checking:\n",
    "            # Average Training Loss\n",
    "            train_avg_loss = float(torch.tensor([x[\"loss\"] for x in train_step_outputs]).mean().cpu().numpy())\n",
    "            self.log('train_avg_loss', train_avg_loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        if not self.trainer.sanity_checking:\n",
    "            # Scoring\n",
    "            idxs = torch.cat([x[\"idxs\"] for x in val_step_outputs]).detach().cpu().numpy()\n",
    "            val_texts = [self.trainer.datamodule.val_texts[idx] for idx in idxs]\n",
    "            val_labels = [self.trainer.datamodule.val_labels[idx] for idx in idxs]\n",
    "            predictions = np.squeeze(torch.cat([x[\"preds\"].sigmoid() for x in val_step_outputs]).detach().cpu().numpy())\n",
    "            char_probs = get_char_probs(val_texts, predictions, self.trainer.datamodule.cfg.tokenizer)\n",
    "            results = get_results(char_probs, th=self.th)\n",
    "            preds = get_predictions(results)\n",
    "            score = get_score(val_labels, preds)\n",
    "            self.log('val_avg_f1', score, on_epoch=True, prog_bar=True)\n",
    "\n",
    "            # Average Validation Loss\n",
    "            val_avg_loss = float(torch.tensor([x[\"loss\"] for x in val_step_outputs]).mean().cpu().numpy())\n",
    "            self.log('val_avg_loss', val_avg_loss, on_epoch=True, prog_bar=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-17T22:45:36.167989Z",
     "iopub.execute_input": "2022-03-17T22:45:36.168449Z",
     "iopub.status.idle": "2022-03-17T22:45:36.191053Z",
     "shell.execute_reply.started": "2022-03-17T22:45:36.168410Z",
     "shell.execute_reply": "2022-03-17T22:45:36.190245Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "    predictions_ = np.concatenate(preds)\n",
    "    return predictions_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" Data Loading \"\"\"\n",
    "test = pd.read_csv(os.path.join(CSV_DATA_PATH, 'test.csv'))\n",
    "submission = pd.read_csv(os.path.join(CSV_DATA_PATH, 'sample_submission.csv'))\n",
    "features = pd.read_csv(os.path.join(CSV_DATA_PATH, 'features.csv'))\n",
    "patient_notes = pd.read_csv(os.path.join(CSV_DATA_PATH, 'patient_notes.csv'))\n",
    "test = test.merge(features, on=['feature_num', 'case_num'], how='left')\n",
    "test = test.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n",
    "\n",
    "\"\"\" Loop through each model and make inference \"\"\"\n",
    "predictions = []\n",
    "for model_files in all_model_files:\n",
    "    config_path, ckpt_path = model_files[0], model_files[1]\n",
    "\n",
    "    \"\"\" Config File \"\"\"\n",
    "    CFG = MODEL_GROUP\n",
    "    with open(config_path, 'r') as file:\n",
    "        CFG = yaml.safe_load(file)\n",
    "    file.close()\n",
    "    CFG = dict2obj(CFG)\n",
    "\n",
    "    \"\"\" Tokenizer \"\"\"\n",
    "    print(f'About to load tokenizer: {CFG.model}')\n",
    "    if \"large\" in CFG.model:\n",
    "        CFG.tokenizer = DebertaV2TokenizerFast.from_pretrained(PATHS['input'] / 'get-token/tokenizer')\n",
    "    else:\n",
    "        CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model_repo)\n",
    "    print('LOADED TOKENIZER')\n",
    "\n",
    "    \"\"\" Test Dataset \"\"\"\n",
    "    test_dataset = TestDataset(CFG, test)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=CFG.batch_size,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=False,\n",
    "                             )\n",
    "    print(\"LOADED TEST DATASETS\")\n",
    "\n",
    "    \"\"\" Load Inference Model \"\"\"\n",
    "    autoconfig_path = PATHS['input'] / CFG.model\n",
    "    automodel_path = ckpt_path\n",
    "    print(f'LOAD MODEL: {ckpt_path}\\n'\n",
    "          f'autoconfig_path: {autoconfig_path}\\n'\n",
    "          f'automodel_path: {automodel_path}\\n')\n",
    "    nbme_model = BaseLineModel.load_from_checkpoint(ckpt_path)\n",
    "    # nbme_model = BaseLineModel(model_repo=CFG.model,\n",
    "    #                            autoconfig_path=autoconfig_path,\n",
    "    #                            automodel_path=automodel_path,\n",
    "    #                            dropout_rate=CFG.fc_dropout).load_from_checkpoint(ckpt_path)\n",
    "    # nbme_model = BaseLineModel(model_repo=CFG.model)\n",
    "    nbme_model = BaseLineModel.load_from_checkpoint(ckpt_path, autoconfig_path=autoconfig_path, automodel_path=automodel_path)\n",
    "    nbme_model.to(DEVICE)\n",
    "    nbme_model.freeze()\n",
    "    nbme_model.eval()\n",
    "    print(f'LOADED BASE MODEL: {ckpt_path}')\n",
    "    prediction = inference_fn(test_loader, nbme_model, DEVICE)\n",
    "    prediction = prediction.reshape((len(test), CFG.max_len))\n",
    "    char_probs = get_char_probs(test['pn_history'].values, prediction, CFG.tokenizer)\n",
    "    predictions.append(char_probs)\n",
    "    del nbme_model, prediction, char_probs\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'Complted Inference: {ckpt_path}\\n')\n",
    "\n",
    "predictions = np.mean(predictions, axis=0)\n",
    "\n",
    "\"\"\" Submission \"\"\"\n",
    "print('Started Submission Section')\n",
    "results = get_results(predictions, th=0.1)\n",
    "submission['location'] = results\n",
    "print(submission.head())\n",
    "submission[['id', 'location']].to_csv('submission.csv', index=False)\n",
    "print('Completed Submission')\n",
    "print('End of Inference')\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-17T22:45:36.194208Z",
     "iopub.execute_input": "2022-03-17T22:45:36.194770Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to load tokenizer: microsoft/deberta-v3-large\n",
      "LOADED TOKENIZER\n",
      "LOADED TEST DATASETS\n",
      "LOAD MODEL: input/nbme-17y1th7h/17y1th7h_zi09ze76/epoch=2-step=4289.ckpt\n",
      "autoconfig_path: input/microsoft/deberta-v3-large\n",
      "automodel_path: input/nbme-17y1th7h/17y1th7h_zi09ze76/epoch=2-step=4289.ckpt\n",
      "\n",
      "Save Hyperparameters: None\n",
      "Loading AutoConfig inside Model Class: input/microsoft/deberta-v3-large/config.json\n",
      "\tLoaded AutoConfig inside Model Class\n",
      "Loading AutoModel inside Model Class: input/microsoft/deberta-v3-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at input/microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded AutoModel inside Model Class\n",
      "Save Hyperparameters: None\n",
      "Loading AutoConfig inside Model Class: input/microsoft/deberta-v3-large\n",
      "\tLoaded AutoConfig inside Model Class\n",
      "Loading AutoModel inside Model Class: input/nbme-17y1th7h/17y1th7h_zi09ze76/epoch=2-step=4289.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at input/nbme-17y1th7h/17y1th7h_zi09ze76/epoch=2-step=4289.ckpt were not used when initializing DebertaV2Model: ['pytorch-lightning_version', 'native_amp_scaling_state', 'state_dict', 'hparams_name', 'lr_schedulers', 'global_step', 'callbacks', 'epoch', 'hyper_parameters', 'optimizer_states']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2Model were not initialized from the model checkpoint at input/nbme-17y1th7h/17y1th7h_zi09ze76/epoch=2-step=4289.ckpt and are newly initialized: ['encoder.layer.17.attention.self.key_proj.weight', 'encoder.layer.13.attention.self.query_proj.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query_proj.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.3.attention.self.key_proj.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value_proj.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query_proj.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query_proj.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.23.attention.self.key_proj.weight', 'encoder.layer.17.attention.self.value_proj.weight', 'encoder.layer.11.attention.self.query_proj.bias', 'encoder.layer.19.attention.self.key_proj.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.23.attention.self.query_proj.bias', 'encoder.layer.11.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.attention.self.value_proj.weight', 'encoder.layer.21.attention.self.value_proj.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.7.attention.self.key_proj.weight', 'encoder.layer.7.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.20.attention.self.key_proj.weight', 'encoder.layer.13.attention.self.key_proj.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.query_proj.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.7.attention.self.query_proj.bias', 'encoder.layer.6.attention.self.query_proj.weight', 'encoder.layer.3.attention.self.key_proj.weight', 'encoder.layer.0.attention.self.value_proj.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query_proj.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.12.attention.self.key_proj.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key_proj.weight', 'encoder.layer.12.attention.self.query_proj.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key_proj.bias', 'encoder.layer.5.attention.self.key_proj.bias', 'encoder.layer.12.attention.self.value_proj.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value_proj.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key_proj.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.12.attention.self.key_proj.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query_proj.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.19.attention.self.key_proj.bias', 'encoder.layer.10.attention.self.query_proj.weight', 'encoder.layer.8.attention.self.value_proj.bias', 'encoder.layer.6.attention.self.query_proj.bias', 'encoder.layer.16.attention.self.query_proj.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.1.attention.self.key_proj.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.20.attention.self.query_proj.weight', 'encoder.layer.7.attention.self.query_proj.weight', 'encoder.layer.0.attention.self.query_proj.weight', 'encoder.layer.9.attention.self.value_proj.bias', 'encoder.layer.7.attention.self.value_proj.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.17.attention.self.query_proj.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query_proj.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value_proj.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query_proj.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.17.attention.self.query_proj.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key_proj.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key_proj.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value_proj.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.1.attention.self.value_proj.bias', 'encoder.layer.20.attention.self.key_proj.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key_proj.bias', 'encoder.layer.15.attention.self.query_proj.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value_proj.bias', 'encoder.layer.9.attention.self.key_proj.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.query_proj.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.key_proj.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.5.attention.self.query_proj.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.attention.self.key_proj.weight', 'encoder.layer.19.attention.self.value_proj.bias', 'encoder.layer.16.attention.self.value_proj.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.22.attention.self.value_proj.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.11.attention.self.key_proj.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.14.attention.self.query_proj.bias', 'encoder.layer.18.attention.self.key_proj.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value_proj.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.13.attention.self.value_proj.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.value_proj.weight', 'encoder.layer.2.attention.self.key_proj.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.4.attention.self.value_proj.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query_proj.weight', 'encoder.rel_embeddings.weight', 'encoder.layer.5.attention.self.value_proj.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.20.attention.self.value_proj.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.21.attention.self.value_proj.weight', 'encoder.layer.21.attention.self.query_proj.bias', 'encoder.layer.8.attention.self.key_proj.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.18.attention.self.query_proj.bias', 'encoder.layer.22.attention.self.query_proj.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.self.value_proj.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key_proj.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.self.query_proj.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query_proj.bias', 'encoder.layer.3.attention.self.query_proj.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query_proj.bias', 'encoder.layer.6.attention.self.key_proj.bias', 'encoder.layer.4.attention.self.value_proj.weight', 'encoder.layer.14.attention.self.query_proj.weight', 'encoder.layer.16.attention.self.value_proj.weight', 'encoder.layer.6.attention.self.key_proj.weight', 'encoder.layer.22.attention.self.value_proj.weight', 'encoder.layer.20.attention.self.value_proj.weight', 'encoder.layer.14.attention.self.key_proj.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.14.attention.self.key_proj.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.2.attention.self.key_proj.weight', 'encoder.layer.9.attention.self.query_proj.bias', 'encoder.layer.7.attention.self.value_proj.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.value_proj.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.18.attention.self.query_proj.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.21.attention.self.query_proj.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.14.attention.self.value_proj.weight', 'encoder.layer.2.attention.self.value_proj.bias', 'encoder.layer.9.attention.self.key_proj.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query_proj.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key_proj.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value_proj.weight', 'encoder.layer.3.attention.self.value_proj.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.self.value_proj.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query_proj.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.self.value_proj.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query_proj.weight', 'encoder.layer.15.attention.self.value_proj.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.17.attention.self.value_proj.bias', 'encoder.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query_proj.weight', 'encoder.layer.10.attention.self.key_proj.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key_proj.bias', 'encoder.layer.11.attention.self.value_proj.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.21.attention.self.key_proj.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.18.attention.self.value_proj.weight', 'encoder.layer.2.attention.self.query_proj.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.7.attention.self.key_proj.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query_proj.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.LayerNorm.weight', 'encoder.layer.18.attention.self.key_proj.bias', 'encoder.layer.22.attention.self.query_proj.bias', 'encoder.layer.3.attention.self.query_proj.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.self.value_proj.weight', 'encoder.layer.0.attention.self.value_proj.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.16.attention.self.key_proj.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.18.attention.self.value_proj.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key_proj.bias', 'encoder.layer.5.attention.self.key_proj.weight', 'encoder.layer.11.attention.self.key_proj.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.8.attention.self.value_proj.weight', 'encoder.layer.11.attention.self.query_proj.weight', 'encoder.layer.5.attention.self.value_proj.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.15.attention.self.key_proj.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value_proj.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key_proj.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.17.attention.self.key_proj.bias', 'encoder.layer.0.attention.self.key_proj.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.15.attention.self.value_proj.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query_proj.bias', 'encoder.layer.9.attention.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded AutoModel inside Model Class\n",
      "LOADED BASE MODEL: input/nbme-17y1th7h/17y1th7h_zi09ze76/epoch=2-step=4289.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e8b9e9dc1584836aaf1ad5867bba2b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complted Inference: input/nbme-17y1th7h/17y1th7h_zi09ze76/epoch=2-step=4289.ckpt\n",
      "\n",
      "Started Submission Section\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 71>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     69\u001B[0m results \u001B[38;5;241m=\u001B[39m get_results(predictions, th\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m     70\u001B[0m submission[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m results\n\u001B[0;32m---> 71\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(submission\u001B[38;5;241m.\u001B[39mhead())\n\u001B[1;32m     72\u001B[0m submission[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocation\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubmission.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCompleted Submission\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 71>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     69\u001B[0m results \u001B[38;5;241m=\u001B[39m get_results(predictions, th\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m     70\u001B[0m submission[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m results\n\u001B[0;32m---> 71\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(submission\u001B[38;5;241m.\u001B[39mhead())\n\u001B[1;32m     72\u001B[0m submission[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocation\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubmission.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCompleted Submission\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/snap/pycharm-professional/278/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:747\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    745\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[1;32m    746\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[0;32m--> 747\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[1;32m    749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[0;32m/snap/pycharm-professional/278/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:144\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/snap/pycharm-professional/278/plugins/python/helpers/pydev/pydevd.py:1147\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1144\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/snap/pycharm-professional/278/plugins/python/helpers/pydev/pydevd.py:1162\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1159\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1161\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1162\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ]
}